# AI vs. Human Decision Boundaries

**Document**: TASK-121  
**Version**: 1.0.0  
**Created**: 2026-01-14  
**Purpose**: Establish clear boundaries for AI vs. human decision-making domains

---

## ğŸ¯ Core Premise

> **AI provides synthesis. Humans provide judgment.**

SPAR-Kit is designed to enhance human decision-making, not replace it. This document codifies the specific boundary between what AI should do and what humans must do.

---

## ğŸ“Š The AI-Human Decision Matrix

### What AI Does (Synthesis)

| AI Responsibility | Description | Example |
|-------------------|-------------|---------|
| **Aggregate perspectives** | Collect and organize viewpoints | "Here are 4 persona positions on this decision" |
| **Surface tensions** | Identify where views conflict | "The Pragmatist and Visionary disagree on timeline" |
| **Generate options** | Present alternatives discovered | "Three paths emerged from the debate" |
| **Highlight risks** | Flag potential failure modes | "INTERROGATE found 5 watch-outs" |
| **Synthesize themes** | Find convergence patterns | "All personas agree on X, diverge on Y" |
| **Provide confidence** | Indicate certainty levels | "65% confidence based on convergence/reasoning/evidence" |

### What Humans Do (Judgment)

| Human Responsibility | Description | Example |
|---------------------|-------------|---------|
| **Frame the question** | Define what decision matters | "Should we enter market X?" |
| **Select perspectives** | Choose which personas debate | "Include Ethics + Innovation" |
| **Weight priorities** | Decide what matters most | "Security > speed for this decision" |
| **Resolve tensions** | Choose when views conflict | "I side with the Pragmatist here" |
| **Accept or override** | Final approval of recommendations | "Modify: add 3-month pilot phase" |
| **Take accountability** | Own the decision outcome | "I decided to proceed" |
| **Execute action** | Implement the decision | "Team, we're moving forward with X" |

---

## ğŸš¦ The Decision Traffic Light Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DECISION TRAFFIC LIGHT                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  ğŸŸ¢ GREEN â€” AI-Assisted, Human Approved                       â”‚
â”‚  â”œâ”€â”€ High confidence (â‰¥70%)                                   â”‚
â”‚  â”œâ”€â”€ Good persona convergence                                 â”‚
â”‚  â”œâ”€â”€ INTERROGATE phase completed                              â”‚
â”‚  â””â”€â”€ Human has reviewed and approved                          â”‚
â”‚      â†’ ACTION: Proceed with documented approval               â”‚
â”‚                                                                â”‚
â”‚  ğŸŸ¡ YELLOW â€” Enhanced Review Required                         â”‚
â”‚  â”œâ”€â”€ Moderate confidence (50-69%)                             â”‚
â”‚  â”œâ”€â”€ OR: Significant persona disagreement                     â”‚
â”‚  â”œâ”€â”€ OR: Bias detected in synthesis                           â”‚
â”‚  â””â”€â”€ Human must add additional analysis                       â”‚
â”‚      â†’ ACTION: Seek second opinion before proceeding          â”‚
â”‚                                                                â”‚
â”‚  ğŸ”´ RED â€” Human Authority Required                            â”‚
â”‚  â”œâ”€â”€ Low confidence (<50%)                                    â”‚
â”‚  â”œâ”€â”€ OR: High-stakes decision domains                         â”‚
â”‚  â”œâ”€â”€ OR: Ethical concerns flagged                             â”‚
â”‚  â”œâ”€â”€ OR: INTERROGATE phase skipped                            â”‚
â”‚  â””â”€â”€ AI recommendation is advisory only                       â”‚
â”‚      â†’ ACTION: Do NOT proceed without additional validation   â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ›‘ Absolute Boundaries

### AI Will NEVER:

1. **Make final decisions** without human approval
2. **Execute actions** on behalf of users
3. **Hide uncertainty** from users
4. **Suppress minority viewpoints** from synthesis
5. **Store or transmit sensitive data** beyond session scope
6. **Claim certainty** when data is insufficient
7. **Override human judgment** even when confidence is high

### Humans MUST Always:

1. **Review every recommendation** before acting
2. **Apply contextual judgment** AI cannot access
3. **Consider ethical implications** beyond AI analysis
4. **Accept accountability** for decisions made
5. **Validate assumptions** AI has made
6. **Check for missing perspectives** AI may not represent
7. **Document their reasoning** when overriding AI

---

## ğŸ“‹ Decision Domain Classification

### ğŸŸ¢ AI Can Recommend (Human Approves)

| Domain | Why AI Helps | Human Role |
|--------|-------------|------------|
| Strategic planning | Aggregates perspectives | Final direction |
| Product roadmaps | Surfaces trade-offs | Priority decisions |
| Team structure | Explores options | Fit/culture judgment |
| Investment priorities | Risk analysis | Risk appetite decision |
| Tech stack choices | Technical comparison | Context + legacy |

### ğŸŸ¡ AI Assists (Human Leads)

| Domain | Why AI Helps | Human Role |
|--------|-------------|------------|
| Hiring decisions | Reduce bias, surface candidates | Cultural fit, potential |
| Performance reviews | Data aggregation | Relationship context |
| Partnership choices | Due diligence support | Trust judgment |
| Pricing decisions | Market analysis | Brand positioning |

### ğŸ”´ AI Provides Context (Human Decides)

| Domain | Why AI is Limited | Human Role |
|--------|------------------|------------|
| Medical treatment | Liability, individualization | Doctor's clinical judgment |
| Legal strategy | Professional responsibility | Attorney's expertise |
| Safety-critical systems | Failure consequences | Engineer's certification |
| Vulnerable populations | Power dynamics | Ethical oversight |
| Crisis management | Real-time context | Executive authority |

---

## ğŸ”„ The Boundary Enforcement Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 BOUNDARY ENFORCEMENT                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚   1. DECISION INPUT                                          â”‚
â”‚      â””â”€â”€ User frames question                                â”‚
â”‚          â””â”€â”€ [BOUNDARY] Domain classification triggered      â”‚
â”‚                                                              â”‚
â”‚   2. AI SYNTHESIS                                            â”‚
â”‚      â””â”€â”€ SPAR debate runs                                    â”‚
â”‚          â””â”€â”€ [BOUNDARY] AI generates, never decides          â”‚
â”‚                                                              â”‚
â”‚   3. CONFIDENCE SCORING                                      â”‚
â”‚      â””â”€â”€ System rates recommendation                         â”‚
â”‚          â””â”€â”€ [BOUNDARY] Low scores trigger warnings          â”‚
â”‚                                                              â”‚
â”‚   4. BIAS CHECK                                              â”‚
â”‚      â””â”€â”€ System analyzes for bias                            â”‚
â”‚          â””â”€â”€ [BOUNDARY] Bias detection = yellow light        â”‚
â”‚                                                              â”‚
â”‚   5. HUMAN REVIEW                                            â”‚
â”‚      â””â”€â”€ User sees recommendation                            â”‚
â”‚          â””â”€â”€ [BOUNDARY] Override panel required              â”‚
â”‚                                                              â”‚
â”‚   6. HUMAN ACTION                                            â”‚
â”‚      â””â”€â”€ Accept / Modify / Reject                            â”‚
â”‚          â””â”€â”€ [BOUNDARY] All actions logged to audit trail    â”‚
â”‚                                                              â”‚
â”‚   7. EXPORT / EXECUTION                                      â”‚
â”‚      â””â”€â”€ Recommendation becomes action                       â”‚
â”‚          â””â”€â”€ [BOUNDARY] Human accountability recorded        â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Implementation Checklist

### Already Implemented âœ…

- [x] **Confidence scoring** â€” `cli/confidence.js`
- [x] **Transparency indicators** â€” `ThinkingBlock` component
- [x] **Override mechanisms** â€” `OverridePanel.js`
- [x] **Ethical guardrails** â€” `docs/ETHICAL_FRAMEWORK.md`
- [x] **Audit trail** â€” `cli/audit.js`
- [x] **Bias detection** â€” `cli/bias.js`

### To Be Implemented ğŸ”²

- [ ] Domain classification warning system
- [ ] Automatic traffic light assignment
- [ ] Real-time boundary alerts during debate
- [ ] Post-decision follow-up survey

---

## ğŸ“š References

- [Ethical Framework](./ETHICAL_FRAMEWORK.md)
- [Success Metrics](./SUCCESS_METRICS.md)
- [SPAR STASH Modes](https://github.com/synthanai/spar/blob/main/docs/STASH_MODES.md)

---

*SPAR-Kit AI-Human Boundaries v1.0.0 â€” TASK-121 â€” 2026-01-14*
